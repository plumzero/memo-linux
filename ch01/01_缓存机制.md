
[参考: CPU中的缓存、缓存一致性、伪共享和缓存行填充](https://zhuanlan.zhihu.com/p/135462276)

### CPU 缓存

CPU 的运算速度最快，内存的读写速度无法和其速度匹配。假如定义 CPU 的一次存储或访问为一个时钟周期，那么内存的一次运算通常需要几十甚至几百个时钟周期。如果在 CPU 直接读取内存进行运算，那么 CPU 大部分时间都在等待对内存的访问，利用率仅有几十分之一甚至几百分之一。为了解决 CPU 运算速度与内存读写速度不匹配的矛盾，在 CPU 和内存之间引入了 Cache 缓存机制。

Cache 在物理实现上其实就是静态随机访问存储器(Static Random Access Memory,SRAM)，Cache 的运行速度介于 CPU 和内存 DRAM 之间，是在 CPU 和内存之间插入的一组高速缓冲存储器，用来解决两者速度不匹配带来的瓶颈问题。Cache 工作原理就是利用空间局部性和时间局部性原理，通过自有的存储空间，缓存一部分内存中的指令和数据，减少 CPU 访问内存的次数，从而提高系统的整体性能。

CPU 从 Cache 里读取数据，如果缓存命中，就不用再访问内存，效率大大提升；如果缓存未命中，CPU 不仅要重新到内存中取数据，还要缓存一片新的数据到 Cache 中，如果 Cache 已经满了，还要清理 Cache，如果 Cache 中的数据有"Dirty Bit"，还要回写到内存中。这一波操作可能需要几十甚至上面个指令，消耗上百个时钟周期的时间，严重影响了 CPU 的读写效率。为了减少这种情况的发生，可以通过增大 Cache 的容量来提高缓存命中的概率，但是会带来成本的上升。

现代 CPU 一般都是多核结构，一个 CPU 芯片内部会集成多个 Core，每个 Core 都会有自己独立的 L1 Cache，包括 D-Cache 和 I-Cache。在 X86 架构的 CPU 中，一般每个 Core 也会有自己独立的 L2 Cache，L3 Cache 被所有的 Core 共享。而在 ARM 架构的 CPU 中，L2 Cache 则被每簇(Cluster)的 Core 共享，L3 Cache 被所有的 Core 共享。
- L1 Cache: 也叫一级缓存。一般内置在内核旁边，是与 CPU 结合最为紧密的 CPU 缓存。一次访问只需要2~4个时钟周期
- L2 Cache: 也叫二级缓存。空间比 L1 Cache 大，速度比 L1 Cache 略慢。一次访问约需要10多个时钟周期
- L3 Cache: 也叫三级缓存。部分单 CPU 多核心的才会有的缓存，介于多核和内存之间。存储空间已达Mb级别，一次访问约需要数十个时钟周期。

当 CPU 要读取一个数据时，首先从 L1 Cache 查找，命中则返回；若未命中，再从 L2 Cache 中查找，如果还没有则从 L3 Cache 查找(如果有 L3 Cache 的话)。如果还是没有，则从内存中查找，并将读取到的数据逐级放入缓存。

Cache 一般用在高性能处理器中，对于一些低功耗、低成本处理器(如单片机)，可能并没有。原因如下:
- 在 CPU 内集成 Cache 会增加芯片的面积和发热量，不仅功耗增加，芯片的成本也会增加不少。
- 这些处理器本身工作频率就不高(从几十MHz到几百MHz不等)，和 RAM 之间不存在带宽问题。
- 使用 Cache 无法保证实时性。当缓存未命中时，CPU 从 RAM 中读取数据的时间是不确定的，这是嵌入式实时控制场景无法接受的。

### 总线锁和缓存锁

总线锁 ：顾名思义就是，锁住总线。通过处理器发出lock指令，总线接受到指令后，其他处理器的请求就会被阻塞，直到此处理器执行完成。这样，处理器就可以独占共享内存的使用。但是，总线锁存在较大的缺点，一旦某个处理器获取总线锁，其他处理器都只能阻塞等待，多处理器的优势就无法发挥。

于是，经过发展、优化，又产生了缓存锁。

缓存锁：不需锁定总线，只需要“锁定”被缓存的共享对象（实际为：缓存行）即可，接受到lock指令，通过缓存一致性协议，维护本处理器内部缓存和其他处理器缓存的一致性。相比总线锁，会提高cpu利用率。

但是缓存锁也不是万能，有些场景和情况依然必须通过总线锁才能完成。

这里又出现了两个新概念：缓存行和缓存一致性协议

### 缓存行

缓存锁会“锁定”共享对象，如果仅锁定所用对象，那么有大有小、随用随取，对于CPU来说利用率还达不到最大化。所以采用，一次获取一整块的内存数据，放入缓存。那么这一块数据，通常称为缓存行（cache line）。缓存行（cache line）是CPU缓存中可分配、操作的最小存储单元。与CPU架构有关，通常有32字节、64字节、128字节不等。目前64位架构下，64字节最为常用。

### 缓存一致性协议

每个处理器都有自己的高速缓存，而又共享同一主内存。当多个处理器都涉及同一块主内存区域的更改时，将导致各自的的缓存数据不一致。那同步到主内存时该以谁的缓存数据为准呢？为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作，来保证处理器间缓存的一致性。这类协议有MSI、MESI、MOSI等。

下面重点介绍应用较为广泛的MESI协议。MESI是Modified（修改）、Exclusive（独占）、Shared（共享）、Invaild（失效）四种状态的缩写，是用来修饰缓存行的状态。在每个缓存行前额外使用2bit，来表示此四种状态。

- Modified（修改）：该缓存行仅出现在此cpu缓存中，缓存已被修改，和内存中不一致，等待同步至内存。- Exclusive（独占）：该缓存行仅出现在此cpu缓存中，缓存和内存中保持一致。
- Shared（共享）：该缓存行可能出现在多个cpu缓存中，且多个cpu缓存的缓存行和内存中的数据一致。
- Invalid（失效）：由于其他cpu修改了缓存行，导致本cpu中的缓存行失效。

在MESI协议中，每个缓存行不仅知道自己的读写操作，而且也监听其它缓存行的读写操作。每个缓存行的状态根据本cpu和其它cpu的读写操作在4个状态间进行迁移。

它的监听（嗅探）机制:
- 当缓存行处于Modified状态时，会时刻监听其他cpu对该缓存行对应主内存地址的读取操作，一旦监听到，将本cpu的缓存行写回内存，并标记为Shared状态
- 当缓存行处于Exclusive状态时，会时刻监听其他cpu对该缓存行对应主内存地址的读取操作，一旦监听到，将本cpu的缓存行标记为Shared状态
- 当缓存行处于Shared状态时，会时刻监听其他cpu对使缓存行失效的指令（即其他cpu的写入操作），一旦监听到，将本cpu的缓存行标记为Invalid状态（其他cpu进入Modified状态）
- 当缓存行处于Invalid状态时，从内存中读取，否则直接从缓存读取

总结:
当某个cpu修改缓存行数据时，其他的cpu通过监听机制获悉共享缓存行的数据被修改，会使其共享缓存行失效。本cpu会将修改后的缓存行写回到主内存中。此时其他的cpu如果需要此缓存行共享数据，则从主内存中重新加载，并放入缓存，以此完成了缓存一致性。


### 伪共享(false sharing)问题

缓存一致性协议针对的是最小存取单元：缓存行。依照64字节的缓存行为例，内存中连续的64字节都会被加载到缓存行中，除了目标数据还会有其他数据。

假如变量x和变量y共处在同一缓存行中，core1需要操作变量x，core2需要操作变量y。
- core1修改缓存行内的变量x后，按照缓存一致性协议，core2需将缓存行置为失效，core1将最新缓存行数据写回内存。
- core2需重新从内存中加载包含变量y的缓存行数据，并放置缓存。如果core2修改变量y，需要core1将缓存行置为失效，core2将最新缓存写回内存。
- core1或其他处理器如需操作同一缓存行内的其他数据，同上述步骤。

上述例子，就是缓存行的伪共享问题。总结来说，就是多核多线程并发场景下，多核要操作的不同变量处于同一缓存行，某cpu更新缓存行中数据，并将其写回缓存，同时其他处理器会使该缓存行失效，如需使用，还需从内存中重新加载。这对效率产生了较大的影响。

### 伪共享解决方案(如: 缓存行填充)

伪共享问题的解决思路有也很典型：空间换时间。

以64字节的缓存行为例，伪共享问题产生的前提是，并发情况下，不同cpu对缓存行中不同变量的操作引起的。那么，如果把缓存行中仅存储目标变量，其余空间采用“无用”数据填充补齐64字节，就不会才产生伪共享问题。这种方式就是：缓存行填充（也称缓存行对齐）。

- [缓存行填充与否对比测试](t/02_cacheline_cmp.cpp)
- 

### Linux 下查看 CPU 高速缓存信息(VM+Ubuntu)

查看 CPU 的数量
```s
  # ls /sys/devices/system/cpu
  cpu0  cpu2  cpufreq  isolated    modalias  online    power    smt     vulnerabilities
  cpu1  cpu3  cpuidle  kernel_max  offline   possible  present  uevent
```
当前系统有四颗 CPU 。

查看 CPU 缓存(以第一颗 CPU(cpu0) 为例)
```s
  # ls /sys/devices/system/cpu/cpu0/cache/
  index0  index1  index2  index3  power  uevent
```
当前系统缓存一共有三级，其中 index0 和 index1 是一级缓存(分别代表 D-Cache 和 I-Cache)，index2 是二级缓存，index3 是三级缓存。

查看一级缓存 D-Cache 缓存的信息
```s
  # cat /sys/devices/system/cpu/cpu0/cache/index0/level
  1
  # cat /sys/devices/system/cpu/cpu0/cache/index0/type
  Data
  # cat /sys/devices/system/cpu/cpu0/cache/index0/size
  32K
```
index0 缓存是一级缓存，类型是 D-Cache, 容量是 32K 。

查看一级缓存 I-Cache 缓存的信息
```s
  # cat /sys/devices/system/cpu/cpu0/cache/index1/level
  1
  # cat /sys/devices/system/cpu/cpu0/cache/index1/type
  Instruction
  # cat /sys/devices/system/cpu/cpu0/cache/index1/size
  32K
```
index1 缓存是一级缓存，类型是 I-Cache, 容量是 32K 。

查看二级缓存的信息
```s
  # cat /sys/devices/system/cpu/cpu0/cache/index2/level
  2
  # cat /sys/devices/system/cpu/cpu0/cache/index2/type
  Unified
  # cat /sys/devices/system/cpu/cpu0/cache/index2/size
  256K
```

查看三级缓存的信息
```s
  # cat /sys/devices/system/cpu/cpu0/cache/index3/level
  3
  # cat /sys/devices/system/cpu/cpu0/cache/index3/type
  Unified
  # cat /sys/devices/system/cpu/cpu0/cache/index3/size
  6144K
```
